# AI: Accelerated Incompetence
- URL: https://www.slater.dev/accelerated-incompetence/
- Added At: 2025-05-30 08:39:36
- [Link To Text](2025-05-30-ai-accelerated-incompetence_raw.md)

## TL;DR
文章警告过度依赖AI编程工具会导致开发者批判性思维退化，指出AI无法掌握程序设计的核心理念，只能生成表面代码而无法抵抗系统熵增。作者呼吁工程师应将AI视为工具而非拐杖，继续培养基本工程能力。

## Summary
1. **文章主旨**：
   - 作者Doug Slater认为在软件工程中过度依赖大型语言模型（LLM）会加速能力退化，AI无法替代人类的批判性思维。

2. **LLM的风险**：
   - **输出风险**：
     - LLM可能生成明显错误的代码（如无法编译的代码）
     - 更危险的是生成难以察觉的逻辑错误
     - 风险在非技术人员（如项目经理）使用LLM生成代码时更高
   - **输入风险**：
     - LLM不会质疑存在问题的提示
     - 无法识别XY问题（用户询问错误的问题）
   - **未来效率风险**：
     - AI可能快速降低代码库质量
     - 类比：就像囤积症患者的房屋，外表正常但内部功能失调
   - **用户幼稚化风险**：
     - 高级工程师失去学习机会，批判性思维能力退化
       - 引用微软研究：AI驱动的信心常以牺牲批判性思维为代价
       - 需要"有思考的、有意的AI协作"
       - LLM提供"成品思维"，剥夺了思维发展的过程
     - 初级工程师无法发展关键技能，也无法指导未来的新人
   - **失去乐趣**：
     - 许多开发者报告AI剥夺了他们的心流状态和创造乐趣
     - AI生成的代码难以阅读和修改

3. **程序理论**：
   - Peter Naur的观点：
     - 程序不是源代码，而是共享的心理构建（理论或设计）
     - 价值在于设计而非代码
   - 思想实验：
     - 两个团队分别开发国际象棋程序
     - 拥有程序理论的团队能更好地添加新功能
   - LLM的局限：
     - 无法掌握程序理论（受限于上下文窗口）
     - 只有人类能获得并保留程序理论

4. **程序熵**：
   - Fred Brooks的观点：
     - 程序构建是熵减过程，维护是熵增过程
     - 符合设计的修改能减缓熵增
   - LLM的局限：
     - 只能在文本层面工作，无法进行概念性思考
     - 倾向于做出不必要和奇怪的修改
     - 只有人类能减少或抵抗复杂性

5. **结论**：
   - LLM可能加速能力退化，但无法替代人类工程
   - 过度使用AI的公司将承担长期成本
   - 工程师应：
     - 将AI视为工具而非拐杖
     - 继续投资2019年就被认为有价值的基本工程技能

6. **未来计划**：
   - 作者计划未来撰写关于如何缓解这些风险的文章
   - 邀请读者订阅邮件列表

7. **参考文献**：
   - 包含10个引用来源，涵盖：
     - 引导性问题
     - XY问题
     - 技术雷达报告
     - 编程作为工艺
     - 思维相关文章
     - AI编码的隐藏成本
     - 程序理论
     - 复杂性
     - 技术成熟度曲线
